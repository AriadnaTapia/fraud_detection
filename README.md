# ğŸ’³ Credit Card Fraud Detection

Un proyecto de **Machine Learning** para detectar transacciones fraudulentas en tarjetas de crÃ©dito.  
Se compararon distintos algoritmos para evaluar cuÃ¡l ofrece el mejor balance entre **precisiÃ³n y sensibilidad (recall)** en un dataset altamente desbalanceado.

---

## ğŸ“Š Contexto

El fraude con tarjetas de crÃ©dito representa **millones de pÃ©rdidas anuales** en la industria financiera.  
El reto principal en este problema es que los fraudes son extremadamente raros:  
en este dataset pÃºblico (Kaggle) **menos del 0.17% de las transacciones son fraudulentas**.

ğŸ‘‰ El objetivo fue desarrollar un modelo de clasificaciÃ³n que logre **detectar la mayor cantidad de fraudes posible (alto recall)** sin generar demasiadas falsas alarmas.

---

## ğŸ” MetodologÃ­a

1. **ExploraciÃ³n de datos (EDA):**
   - 284,807 transacciones totales.
   - Solo 492 casos de fraude (0.17%).
   - No se encontraron valores nulos; se eliminaron duplicados.

2. **Preprocesamiento:**
   - Escalado automÃ¡tico de `V1...V28` (PCA).
   - NormalizaciÃ³n de `Amount` y `Time` cuando fue necesario.
   - Ajuste de desbalance con `class_weight='balanced'`.

3. **Entrenamiento de modelos:**
   - ğŸŒ² Random Forest  
   - âš¡ LightGBM  
   - ğŸ± CatBoost  

4. **EvaluaciÃ³n:**
   - ROC-AUC  
   - PR-AUC (mÃ¡s relevante en dataset desbalanceado).  
   - Classification Report.  
   - Matriz de confusiÃ³n.

---

## ğŸ“ˆ Resultados

| Modelo        | ROC-AUC | PR-AUC | PrecisiÃ³n (fraudes) | Recall (fraudes) | F1-score |
|---------------|:-------:|:------:|:-------------------:|:----------------:|:--------:|
| ğŸŒ² Random Forest | 0.966 | 0.819 | 0.947 | 0.747 | 0.835 |
| âš¡ LightGBM      | 0.973 | 0.818 | 0.899 | 0.747 | 0.816 |
| ğŸ± CatBoost      | **0.977** | 0.792 | 0.675 | **0.810** | 0.737 |

ğŸ”¹ **Random Forest:** mÃ¡s conservador, casi sin falsos positivos pero menor recall.  
ğŸ”¹ **LightGBM:** balance intermedio y rÃ¡pido en entrenamiento.  
ğŸ”¹ **CatBoost:** mejor recall (81%), reduciendo fraudes no detectados aunque con mÃ¡s falsas alarmas.

---

## ğŸ’¡ Conclusiones

- Todos los modelos alcanzaron un rendimiento sobresaliente (**ROC-AUC > 0.96**).  
- **CatBoost** resultÃ³ el mÃ¡s adecuado si la prioridad es **detectar fraudes** (maximizar recall).  
- En un entorno real, **ajustar el umbral de decisiÃ³n** puede ayudar a equilibrar precisiÃ³n y recall segÃºn las necesidades del negocio.  

ğŸ‘‰ El proyecto demuestra cÃ³mo enfrentar problemas de **clases altamente desbalanceadas** en la prÃ¡ctica.

---

## ğŸš€ PrÃ³ximos pasos

- Ajuste dinÃ¡mico de umbrales para optimizar recall/precisiÃ³n.  
- Probar oversampling (SMOTE) y detecciÃ³n no supervisada (Isolation Forest, Autoencoders).  
- Implementar el modelo en un flujo de **detecciÃ³n en tiempo real**.

---

## ğŸ› ï¸ TecnologÃ­as utilizadas

- Python  
- Pandas, NumPy  
- Scikit-learn  
- LightGBM, CatBoost  
- Matplotlib, Seaborn  

---

## ğŸ“‚ Recursos

- ğŸ“Š Dataset: [Credit Card Fraud Detection (Kaggle)](https://www.kaggle.com/mlg-ulb/creditcardfraud)  
- ğŸ““ Notebook: *incluido en este repositorio*  
- âœ¨ Autor: *Ariadna Rosas Tapia*

---
